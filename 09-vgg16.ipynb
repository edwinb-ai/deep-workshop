{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "from keras.layers import Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de lote para el optimizador\n",
    "batch_size = 64\n",
    "# Número de clases, ya se sabe por que se conoce el conjunto de datos\n",
    "# pero si no, se puede hacer de forma programática\n",
    "num_classes = 100\n",
    "# Número de épocas, dejar como está porque es suficiente\n",
    "epocas = 3\n",
    "# Parámetro de regularización L2 (Ridge)\n",
    "regular_param_l2 = l2(5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec1c1b17d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[56, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a float32 para mejor manejo\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "# Normalizar los valores de las imágenes\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (50000, 32, 32, 3)\n",
      "50000 Muestras de entrenamiento\n",
      "10000 Muestras de prueba\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del conjunto de entrenamiento:\", x_train.shape)\n",
    "print(x_train.shape[0], \"Muestras de entrenamiento\")\n",
    "print(x_test.shape[0], \"Muestras de prueba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación One Hot para las etiquetas\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquitectura = [\n",
    "    # Primera capa de características\n",
    "    Conv2D(64, kernel_size=(3, 3), padding=\"same\",\n",
    "          input_shape=x_train.shape[1:],\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(64, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Segunda capa de características\n",
    "    Conv2D(128, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(128, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Tercera capa de características\n",
    "    Conv2D(256, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(256, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(256, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Cuarta capa de características\n",
    "    Conv2D(512, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(512, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(512, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Quinta capa de características\n",
    "    Conv2D(512, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(512, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(512, kernel_size=(3, 3), padding=\"same\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Primera capa totalmente conectada\n",
    "    Flatten(),\n",
    "    Dense(4096, activation=\"relu\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation=\"relu\",\n",
    "          kernel_regularizer=regular_param_l2),\n",
    "    Dropout(0.5),\n",
    "    # Salida de la CNN\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Early Stopping\n",
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", verbose=1, patience=15)\n",
    "# Guardar siempre el mejor modelo encontrado en base a la precisión de validación\n",
    "mc = ModelCheckpoint(\"mejor_modelo.h5\", monitor=\"val_acc\", mode=\"auto\", verbose=1, save_best_only=True)\n",
    "# Ajustar el ratio de aprendizaje\n",
    "lr_ajuste = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = Sequential(arquitectura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=SGD(1e-2, momentum=0.9),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,  # si es positivo, la media del conjunto de datos es 0\n",
    "        samplewise_center=False,  # si es positivo, la medida de cada ejemplo es 0\n",
    "        featurewise_std_normalization=False,  # divide el conjunto de datos por la desviación estándar\n",
    "        samplewise_std_normalization=False,  # divide cada ejemplo por su propia desviación estándar\n",
    "        zca_whitening=True,  # aplicar ruido tipo Zero-phase Component Analysis\n",
    "        zca_epsilon=1e-06,  # valor del ruido tipo ZCA\n",
    "        rotation_range=0,  # se rota aleatoriamente la imagen, el valor es entero de 0 a 180\n",
    "        # traslación horizontal aleatoria, la fracción representa cuánto\n",
    "        width_shift_range=0.1,\n",
    "        # traslación vertical aleatoria, la fracción representa cuánto\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.0,  # valor para distorsión\n",
    "        zoom_range=0.2,  # valor para acercamiento\n",
    "        channel_shift_range=0.,  # cambio de canales, de forma aleatoria\n",
    "        # modo para rellenado de pixeles fuera de la imagen\n",
    "        fill_mode=\"nearest\",\n",
    "        cval=0.0,  # en caso de que el rellenado sea \"constant\"\n",
    "        horizontal_flip=True,  # reflexión horizontal aleatoria de las imágenes\n",
    "        vertical_flip=True,  # reflexión vertical aleatoria de las imágenes\n",
    "        # factor de reescalamiento (se aplica primero antes que cualquier transformación)\n",
    "        rescale=None,\n",
    "        # algún tipo de función definida por el usuario que haga transformaciones\n",
    "        # i.e. filtro de Borel, transformada de Fourier, ruido rosa, etc.\n",
    "        preprocessing_function=None,\n",
    "        # especificar el tipo de datos que se están ingresando\n",
    "        data_format=None,\n",
    "        # fracción de imágenes para separar en entrenamieto y validación\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_load = load_model(\"mejor_modelo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30065, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30065 to 0.30498, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.30498 to 0.32319, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.32319\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.32319 to 0.32834, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.32834 to 0.35665, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.35665\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.35665 to 0.36167, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.36167\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.36167 to 0.36903, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.36903 to 0.38787, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.38787\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.38787 to 0.39080, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.39080 to 0.39780, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.39780 to 0.40148, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.40148 to 0.41356, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.41356\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.41356 to 0.41866, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.41866 to 0.42739, saving model to mejor_modelo.h5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.42739\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.42739\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.42739\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.42739\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-36db75a0dde8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_ajuste\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                             verbose=0)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "historia_vgg16 = vgg16_load.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    subset=\"training\"),\n",
    "                                    epochs=epocas,\n",
    "                                    validation_data=datagen.flow(x_train, y_train,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                subset=\"validation\"),\n",
    "                                    steps_per_epoch=np.ceil(len(x_train) // batch_size),\n",
    "                                    validation_steps=np.ceil(len(x_train) // batch_size),\n",
    "                                    workers=4,\n",
    "                                    callbacks=[es, mc, lr_ajuste],\n",
    "                            verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
