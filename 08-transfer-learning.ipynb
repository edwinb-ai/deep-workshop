{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje transferible (Transfer Learning)\n",
    "\n",
    "Una de las grandes ventajas de las redes neuronales convolucionales (CNN) es su habilidad para extraer características básicas y muy precisas de los conjuntos de datos. Las primeras capas de las CNN constan de _filtros_ que extraen información como bordes, colores y figuras, por lo que se pretende utilizar este tipo de información en un conjunto de datos diferente.\n",
    "\n",
    "La idea es simple y llamativa: si un modelo ha aprendido las formas y características de un conjunto de datos se puede hacer uso de esta información sobre un conjunto de datos **nuevo** que no haya sido visto aún por la CNN. Esto lleva por nombre **transfer learning** y su propósito es utilizar modelos y arquitecturas previamente entrenados para ser utilizados en otro tipo de datos.\n",
    "\n",
    "En este documento se explora una aplicación simple, donde se pretende generalizar el conjunto de datos y el modelo empleado a un nuevo conjunto de datos. El ejemplo aquí presentado está basado en el [ejemplo](https://keras.io/examples/mnist_transfer_cnn/) de `keras` sobre _transfer learning._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST\n",
    "\n",
    "El conjunto de datos empleado es el [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) que tiene 10 clases, cada una pertenece a un tipo de prenda o de calzado. La idea de este conjunto de datos (en realidad son imágenes) es que sirva como un reemplazo para el famoso conjunto de datos de dígitos escritos a mano del MNIST.\n",
    "\n",
    "Las imágenes tienen un tamaño de $28 \\times 28$ y están en tono de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de lote para el optimizador\n",
    "batch_size = 64\n",
    "# Número de clases, ya se sabe por que se conoce el conjunto de datos\n",
    "# pero si no, se puede hacer de forma programática\n",
    "num_clases = 5\n",
    "# Número de épocas, dejar como está porque es suficiente\n",
    "epocas = 10\n",
    "# Tamaño de los datos de entrada \n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8286734ad0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAQHElEQVR4nO3dfYwVZZbH8d8BEd95WbADKDKjortuImiLGAwBlQnqH/g2k8HEaDRiAiZDosmiG6LRmJCNutGYaJhApnczK2DUiJNlHUOGZccYsUUXcZCxV9mRoSMSo9NAdATP/tHFpsWuU+2tW7euPN9P0rnd93TVPZb9o+rep6oec3cBOPYNq7sBAK1B2IFEEHYgEYQdSARhBxJxXCtfzMz46B+omLvbYM+X2rOb2Xwz22lmPWa2rMy6AFTLGh1nN7Phkv4oaZ6k3ZLelLTQ3f8QLMOeHahYFXv2GZJ63P1Dd/+rpDWSFpRYH4AKlQn7JEkfD/h5d/bct5jZIjPrNrPuEq8FoKQyH9ANdqjwncN0d18paaXEYTxQpzJ79t2Szhzw8xmS9pRrB0BVyoT9TUnnmtmPzOx4ST+XtL45bQFotoYP4939kJndLekVScMlrXb395rWGYCmanjoraEX4z07ULlKTqoB8MNB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxJB2IFEEHYgEYQdSARhBxLR0imbceyZPHlyWD/77LNza1dccUW47Ndffx3W16+Ppym4/PLLc2sdHR3hsq+88kpYnzTpOzOdfcvatWvDeh3YswOJIOxAIgg7kAjCDiSCsAOJIOxAIgg7kAhmcT3GzZ8/P6w/88wzYX3NmjVh/bzzzgvre/bsya29/fbb4bIXX3xxWP/oo4/C+lNPPZVbKzo/YMqUKWH9scceC+vXXnttWN+1a1dubdiweB/8zTffhPW8WVxLnVRjZrsk9Uk6LOmQu3eWWR+A6jTjDLq57r6vCesBUCHeswOJKBt2l/RbM3vLzBYN9gtmtsjMus2su+RrASih7GH8LHffY2anS3rVzN53980Df8HdV0paKfEBHVCnUnt2d9+TPe6V9KKkGc1oCkDzNRx2MzvZzE498r2kn0ja3qzGADRXmcP4DkkvmtmR9fybu/9HU7pKTNG4apGicdfIhg0bwvqjjz4a1vftq24gZtu2bWF93rx5Yf3gwYO5tf3794fLTp8+Pazfc889YT0aRy9S5v9npOGwu/uHki5sYi8AKsTQG5AIwg4kgrADiSDsQCIIO5AILnFtAyNGjAjrRbdUPlaNGjUqrK9atSqsb9q0KbdWNGw3d+7csH7aaaeF9TKqusSVPTuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4lgyuY2cPjw4crWXXbMtuzykeuvvz6sL1y4MKyPHTs2rPf09OTWrrvuunDZxYsXh/UqVXWJK3t2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSwfXsbaDKseyqr5U///zzw/oTTzyRW/viiy/CZW+//fawPm3atLC+fPny3FrRtfIzZ84M62VFr3/SSSeFy/b29oZ1rmcHEkfYgUQQdiARhB1IBGEHEkHYgUQQdiARjLMfA6Jx+rLXRq9YsSKsd3Z2hvX7778/t7Zly5aGejqi6PyEN954I7d2ySWXlHrtCRMmhPXx48eH9RkzZuTWZs2aFS7b1dWVW+vu7lZfX19j4+xmttrM9prZ9gHPjTWzV83sg+xxTNF6ANRrKIfxv5I0/6jnlkna6O7nStqY/QygjRWG3d03S/rsqKcXSDpyLNElKb7HD4DaNXoPug5375Ukd+81s9PzftHMFkla1ODrAGiSym846e4rJa2U+IAOqFOjQ2+fmNkEScoe9zavJQBVaDTs6yXdmn1/q6SXmtMOgKoUHsab2bOS5kgaZ2a7JT0gaYWkdWZ2h6Q/SfpplU0iFo2lR+O5kvTwww+H9eeeey6sL1tW30DMGWecEdaj6+WnTJkSLjtp0qSwPnXq1LB+wgknhPWzzjort1Z0nf/Bgwdza9HfQmHY3T3vTv1XFi0LoH1wuiyQCMIOJIKwA4kg7EAiCDuQCKZsbgOnnHJKWN+/f39YX7BgQW6t6HbMN954Y6nXLqPsba6Letu+fXtubfr06eGyRUNns2fPDuvR8JgU/7cVXbrb6KXB7NmBRBB2IBGEHUgEYQcSQdiBRBB2IBGEHUgE4+wtUDRuWjReXDQ18ZVX5l+AGI3BD0WV00mXnS765ptvDus9PT25tauvvjpc9s477wzrGzduDOs7d+4M6wcOHMitVXVuA3t2IBGEHUgEYQcSQdiBRBB2IBGEHUgEYQcSwTh7C5SdNnnu3LlhfenSpQ2vu8px9LKefPLJsD5x4sSwPnbs2Nxa0TXhw4cPD+tF26XoFt733ntvbm3Dhg3hso1izw4kgrADiSDsQCIIO5AIwg4kgrADiSDsQCIYZ2+CsmPVM2fODOuvv/56w+svujf74cOHw3qV5s2bF9b7+vrC+pw5c8L6008/nVtbvnx5uGxZH3/8cVg/8cQTc2u9vb3NbkfSEPbsZrbazPaa2fYBzz1oZn82s3eyr2sq6Q5A0wzlMP5XkuYP8vw/u/u07Ovfm9sWgGYrDLu7b5b0WQt6AVChMh/Q3W1m27LD/DF5v2Rmi8ys28y6S7wWgJIaDfvTks6WNE1Sr6TH8n7R3Ve6e6e7dzb4WgCaoKGwu/sn7n7Y3b+R9EtJ8SU+AGrXUNjNbMKAH6+XlD83LoC2UDjObmbPSpojaZyZ7Zb0gKQ5ZjZNkkvaJemuCntsiTJj5WWv+R4/fnxYf/nllxted9G92Yv+u8uaPHlybm306NHhsnfdFf9ZFV3v/tBDD4X1SNlzJ0aOHNnwa7///vsNLxspDLu7Lxzk6VUV9AKgQpwuCySCsAOJIOxAIgg7kAjCDiSCS1wzRUMpHR0dubXPP/88XLboVtBlp+gtM3xWdtgwul2zFA8r3nfffeGya9euDetFQ2vR5b1lp4sucujQobAeXeL61VdfNbsdSezZgWQQdiARhB1IBGEHEkHYgUQQdiARhB1IxA9qnD0aTy4aLy66pXLRFLuRL7/8MqzfcMMNYf3xxx9v+LWLlB1HL9puRbeDjm73XHR+wJIlS8J6karH0iPHHRdHK7qFN+PsAEoh7EAiCDuQCMIOJIKwA4kg7EAiCDuQiB/UOHuZMeOiMdd169aF9Ysuuii3NmZM7uxXkqTNmzeH9YMHD4b1ImXH0iOXXnppWC8ah589e3Zu7aqrrmqop6G+dplx9rLb9Pjjjw/rw4cPz60VnbfRKPbsQCIIO5AIwg4kgrADiSDsQCIIO5AIwg4k4gc1zh4pO+Y6ceLEsL5169bc2qxZs8Jlo3vOS9Kpp54a1otE6y/aLuecc05Y7+7uDuuPPPJIWN+xY0durbe3N1y26Hr3Kq9XLztlc9F2j9Zf2zi7mZ1pZr8zsx1m9p6Z/SJ7fqyZvWpmH2SP8ZklAGo1lMP4Q5Lucfe/lTRT0hIz+ztJyyRtdPdzJW3MfgbQpgrD7u697r41+75P0g5JkyQtkNSV/VqXpOuqahJAed/rPbuZTZE0XdIbkjrcvVfq/wfBzE7PWWaRpEXl2gRQ1pDDbmanSHpe0lJ3/4uZDWk5d18paWW2Dm+kSQDlDWnozcxGqD/ov3b3F7KnPzGzCVl9gqS91bQIoBkK9+zWvwtfJWmHuw+85/F6SbdKWpE9vlS0rhEjRmjcuHG59aLbOW/ZsiW3VnYYprOzM6wvXrw4t3bZZZeFy+7bty+s33LLLWG9p6en4XpfX1+47GuvvRbWV61aFdaLtvtNN90U1iNVXrpbtaLtXlSvwlAO42dJukXSu2b2Tvbc/eoP+Tozu0PSnyT9tJoWATRDYdjd/feS8t6gX9ncdgBUhdNlgUQQdiARhB1IBGEHEkHYgUS09BLXYcOGhZdz3nbbbeHyDzzwQMOvvXPnzrAejeFL8e2gi263XDSmGk3fK0kHDhwI659++mlubf78+eGymzZtCutFt0QeOXJkWP+him71LBWfAzB58uSwfuGFFza87kaxZwcSQdiBRBB2IBGEHUgEYQcSQdiBRBB2IBHm3rqbx1R5p5qpU6eG9aJrzotuJR1dhz969Ohw2aJbRV9wwQVhvWhK51GjRuXWim7XvHr16rDe1dUV1otEt0xu5+vVy96avOjvMZoifNq0aeGyRdx90KtU2bMDiSDsQCIIO5AIwg4kgrADiSDsQCIIO5CIY2acHUA/xtmBxBF2IBGEHUgEYQcSQdiBRBB2IBGEHUhEYdjN7Ewz+52Z7TCz98zsF9nzD5rZn83snezrmurbBdCowpNqzGyCpAnuvtXMTpX0lqTrJP1M0n53f3TIL8ZJNUDl8k6qGcr87L2SerPv+8xsh6RJzW0PQNW+13t2M5siabqkN7Kn7jazbWa22szG5CyzyMy6zay7VKcAShnyufFmdoqk/5T0iLu/YGYdkvZJckkPq/9Q//aCdXAYD1Qs7zB+SGE3sxGSfiPpFXd/fJD6FEm/cfe/L1gPYQcq1vCFMGZmklZJ2jEw6NkHd0dcL2l72SYBVGcon8ZfLum/JL0r6ci9f++XtFDSNPUfxu+SdFf2YV60LvbsQMVKHcY3C2EHqsf17EDiCDuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4kg7EAiCDuQCMIOJIKwA4kg7EAiCDuQiMIbTjbZPkn/O+Dncdlz7ahde2vXviR6a1Qzezsrr9DS69m/8+Jm3e7eWVsDgXbtrV37kuitUa3qjcN4IBGEHUhE3WFfWfPrR9q1t3btS6K3RrWkt1rfswNonbr37ABahLADiagl7GY238x2mlmPmS2ro4c8ZrbLzN7NpqGudX66bA69vWa2fcBzY83sVTP7IHscdI69mnpri2m8g2nGa912dU9/3vL37GY2XNIfJc2TtFvSm5IWuvsfWtpIDjPbJanT3Ws/AcPMZkvaL+lfjkytZWb/JOkzd1+R/UM5xt3/oU16e1DfcxrvinrLm2b8NtW47Zo5/Xkj6tizz5DU4+4fuvtfJa2RtKCGPtqeu2+W9NlRTy+Q1JV936X+P5aWy+mtLbh7r7tvzb7vk3RkmvFat13QV0vUEfZJkj4e8PNutdd87y7pt2b2lpktqruZQXQcmWYrezy95n6OVjiNdysdNc1422y7RqY/L6uOsA82NU07jf/NcveLJF0taUl2uIqheVrS2eqfA7BX0mN1NpNNM/68pKXu/pc6exlokL5ast3qCPtuSWcO+PkMSXtq6GNQ7r4ne9wr6UX1v+1oJ58cmUE3e9xbcz//z90/cffD7v6NpF+qxm2XTTP+vKRfu/sL2dO1b7vB+mrVdqsj7G9KOtfMfmRmx0v6uaT1NfTxHWZ2cvbBiczsZEk/UftNRb1e0q3Z97dKeqnGXr6lXabxzptmXDVvu9qnP3f3ln9Jukb9n8j/j6R/rKOHnL5+LOm/s6/36u5N0rPqP6z7Wv1HRHdI+htJGyV9kD2ObaPe/lX9U3tvU3+wJtTU2+Xqf2u4TdI72dc1dW+7oK+WbDdOlwUSwRl0QCIIO5AIwg4kgrADiSDsQCIIO5AIwg4k4v8AryMxd28CRukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se puede visualizar una de estas imágenes para conocer el conjunto de datos\n",
    "plt.imshow(x_train[82, :, :], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "La idea es separar el conjunto de datos en dos: las **primeras** 5 clases se utilizarán para entrenar al modelo, aprender las características principales y generalizarlas. Después, las **últimas** 5 clases se alimentarán al modelo pero los _filtros_ de características no se actualizarán, solamente se hará una clasificación.\n",
    "\n",
    "Para esto se van a separar los conjuntos de datos, unos con las primeras 5 clases y las clases que restan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar los índices de las primeras 5 clases, entrenamiento y prueba\n",
    "idx_train_lt5 = np.squeeze(y_train < 5)\n",
    "idx_test_lt5 = np.squeeze(y_test < 5)\n",
    "# Tomar los índices de las últimas 5 clases, entrenamiento y prueba\n",
    "idx_train_gte5 = np.squeeze(y_train >= 5)\n",
    "idx_test_gte5 = np.squeeze(y_test >= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los índices de las clases se puede separar el conjunto de datos de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las primeras 5 clases, entrenamiento y prueba, junto con sus etiquetas\n",
    "x_train_lt5 = x_train[idx_train_lt5]\n",
    "y_train_lt5 = y_train[idx_train_lt5]\n",
    "x_test_lt5 = x_test[idx_test_lt5]\n",
    "y_test_lt5 = y_test[idx_test_lt5]\n",
    "# Las últimas 5 clases, entrenamiento y prueba\n",
    "x_train_gte5 = x_train[idx_train_gte5]\n",
    "# A las etiquetas hay que restarles 5 para asegurar que se tienen las últimas\n",
    "y_train_gte5 = y_train[idx_train_gte5] - 5\n",
    "x_test_gte5 = x_test[idx_test_gte5]\n",
    "y_test_gte5 = y_test[idx_test_gte5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar el entrenamiento se crea una función que realiza todas las operaciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, num_classes):\n",
    "    # Reajustar el formato de las imágenes\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    # Normalizar las imágenes\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    # Mostrar información relevante\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # Codificar mediante OneHot\n",
    "    y_train = to_categorical(train[1], num_classes)\n",
    "    y_test = to_categorical(test[1], num_classes)\n",
    "    # Compilar el modelo\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "    # Entrenar el modelo y realizar la validación\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epocas,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura\n",
    "\n",
    "La arquitectura es muy simple, consta de dos capas de 32 unidades de filtros $3 \\times 3$, funciones de activación ReLU. La última capa es totalmente conectada de 128 unidades, y empleando _dropout_ de 25% para los filtros y de 50% para parte totalmente conectada.\n",
    "\n",
    "Aquí la implementación es diferente, se separan los tipos de capas dado que en la primera parte se van a ajustar los filtros de características, pero en la segunda parte se van a omitir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas son las capas de características\n",
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3),\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, kernel_size=(3, 3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "# Y esta es la capa que realiza la clasificación\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_clases),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento: primeras 5 clases\n",
    "\n",
    "En esta parte del entrenamiento se va a entrenar y validar el modelo con las primeras 5 clases que se habían separado desde el principio, durante 10 épocas de entrenamiento. Aquí se van a ajustar los filtros de características y se va a clasificar el conjunto de validación.\n",
    "\n",
    "Este es el modelo que se va a entrenar y genalizará las características para las últimas 5 capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30000, 28, 28, 1)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "Train on 30000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 27s 904us/step - loss: 0.4049 - acc: 0.8620 - val_loss: 0.2417 - val_acc: 0.9126\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 27s 889us/step - loss: 0.2482 - acc: 0.9137 - val_loss: 0.1991 - val_acc: 0.9288\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 26s 880us/step - loss: 0.2123 - acc: 0.9266 - val_loss: 0.2279 - val_acc: 0.9170\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 26s 864us/step - loss: 0.1862 - acc: 0.9350 - val_loss: 0.1853 - val_acc: 0.9330\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 28s 934us/step - loss: 0.1692 - acc: 0.9383 - val_loss: 0.1689 - val_acc: 0.9436\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 27s 894us/step - loss: 0.1538 - acc: 0.9445 - val_loss: 0.1723 - val_acc: 0.9424\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 27s 907us/step - loss: 0.1421 - acc: 0.9476 - val_loss: 0.1683 - val_acc: 0.9488\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 28s 924us/step - loss: 0.1323 - acc: 0.9514 - val_loss: 0.1844 - val_acc: 0.9414\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 27s 893us/step - loss: 0.1251 - acc: 0.9533 - val_loss: 0.1860 - val_acc: 0.9356\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 26s 856us/step - loss: 0.1158 - acc: 0.9566 - val_loss: 0.1819 - val_acc: 0.9432\n",
      "Test score: 0.18193507876992226\n",
      "Test accuracy: 0.9432\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento: últimas 5 capas\n",
    "\n",
    "Ahora se van a _congelar_ las capas de características, esto es que **no se van a actualizar.** El propósito de _transfer learning_ es utilizar las características ya aprendidas en el modelo entrenado y clasificar un conjunto de datos totalmente diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar todas los filtros de convolución\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (30000, 28, 28, 1)\n",
      "30000 train samples\n",
      "5000 test samples\n",
      "Train on 30000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 17s 560us/step - loss: 0.3705 - acc: 0.8854 - val_loss: 0.1008 - val_acc: 0.9644\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 15s 516us/step - loss: 0.1177 - acc: 0.9603 - val_loss: 0.0761 - val_acc: 0.9748\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 16s 543us/step - loss: 0.0864 - acc: 0.9701 - val_loss: 0.0710 - val_acc: 0.9748\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 16s 523us/step - loss: 0.0709 - acc: 0.9741 - val_loss: 0.0700 - val_acc: 0.9774\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 15s 513us/step - loss: 0.0615 - acc: 0.9786 - val_loss: 0.0642 - val_acc: 0.9784\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 15s 503us/step - loss: 0.0550 - acc: 0.9799 - val_loss: 0.0647 - val_acc: 0.9796\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 15s 508us/step - loss: 0.0511 - acc: 0.9817 - val_loss: 0.0630 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 17s 567us/step - loss: 0.0433 - acc: 0.9844 - val_loss: 0.0725 - val_acc: 0.9774\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 16s 521us/step - loss: 0.0411 - acc: 0.9846 - val_loss: 0.0683 - val_acc: 0.9798\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 16s 534us/step - loss: 0.0364 - acc: 0.9854 - val_loss: 0.0677 - val_acc: 0.9818\n",
      "Test score: 0.06765552457415325\n",
      "Test accuracy: 0.9818\n"
     ]
    }
   ],
   "source": [
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "El resultado es excelente, al entrenar el modelo con las _primeras_ 5 capas se obtiene una precisión de validación de 94.2%. Cuando se generaliza este modelo a las _últimas_ 5 capas se obtiene una precisión de 98.2%. Esto implica que la técnica de _transfer learning_ es muy buena cuando se tienen conjuntos de datos con **características semejantes.**\n",
    "\n",
    "En otras ocasiones se puede hacer uso de conjuntos de datos más grandes, de diferentes tipos, para resolver un problema semejante, pero se debe tomar en cuenta que los conjuntos de datos deben de tener _características semejantes_ para que esta técnica funcione adecuadamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
