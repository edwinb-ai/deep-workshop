{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Convolucionales (CNN)\n",
    "\n",
    "Son un tipo de redes neuronales específicamente diseñadas y creadas para tratar con información que tiene topología o estructura de cuadrícula, como series de tiempo y sobre todo, imágenes.\n",
    "\n",
    "Estas redes neuronales se caracterizan por emplear la _convolución_ para aprender las características más básicas de las imágenes que se le suministran, con lo que pueden generalizar los elementos e identificar estructuras muy variadas a partir de estos bloques elementales.\n",
    "\n",
    "## Sobre la convolución\n",
    "\n",
    "Siguiendo el libro [Deep Learning](https://www.deeplearningbook.org/), la operación que emplean las CNN no es técnicamente la convolución sino una operación muy semejante llamanda [relación cruzada (cross-relation)](https://en.wikipedia.org/wiki/Cross-correlation), que es igual a la convolución en un caso particular.\n",
    "\n",
    "La razón de esto es porque computacionalmente es más eficiente programar y ejecutar la _relación cruzada_ que la convolución directamente, y esto es a lo que se le llama _convolución_ en _deep learning._\n",
    "\n",
    "## Caso de estudio: Clasificación de MNIST\n",
    "\n",
    "Para este documento se pretende clasificar el conjunto MNIST con una CNN básica, donde se proponen un par de estructuras elementales como las capas de convolución y de _pooling_. La idea es generar una CNN elemental que demuestre y explique la implementación en `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, datasets, utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros de la CNN\n",
    "\n",
    "Para comenzar se fijarán algunos hiperparámetros de la CNN, en esto caso se toma como ejemplo el [ejercicio de `keras` sobre CNN](https://keras.io/examples/mnist_cnn/) y se va a modificar para este documento.\n",
    "\n",
    "Los hiperparámetros se quedan igual, sobre todo el tamaño de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de lote para el optimizador\n",
    "batch_size = 128\n",
    "# Número de clases, ya se sabe por que se conoce el conjunto de datos\n",
    "# pero si no, se puede hacer de forma programática\n",
    "num_classes = 10\n",
    "# Número de épocas, dejar como está porque es suficiente\n",
    "epochs = 12\n",
    "\n",
    "# Tamaño de las imágenes, ancho y alto\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los datos\n",
    "\n",
    "Se extraen los datos desde la API de `keras` la cual ya separa el conjunto de datos en entrenamiento y prueba. En total el conjunto de datos consta de 70000 imágenes y aquí se separan en 60000 de entrenamiento y 10000 de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para verificar el tamaño de las imágenes y el número de imágenes\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe0e1b91150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAOYElEQVR4nO3dbYxc5XnG8euKbUwxJvHGseMQFxzjFAg0Jl0ZkBFQoVCCIgGKCLGiiFBapwlOQutKUFoVWtHKrRIiSimSKS6m4iWQgPAHmsSyECRqcFmoAROHN+MS4+0aswIDIfZ6fffDjqsFdp5dZs68eO//T1rNzLnnzLk1cPmcmeeceRwRAjD5faDTDQBoD8IOJEHYgSQIO5AEYQeSmNrOjR3i6XGoZrRzk0Aqv9Fb2ht7PFatqbDbPkfS9ZKmSPrXiFhVev6hmqGTfVYzmwRQsDE21K01fBhve4qkGyV9TtLxkpbZPr7R1wPQWs18Zl8i6fmI2BoReyXdJem8atoCULVmwn6kpF+Nery9tuwdbC+33We7b0h7mtgcgGY0E/axvgR4z7m3EbE6InojoneapjexOQDNaCbs2yXNH/X445J2NNcOgFZpJuyPSlpke4HtQyR9SdK6atoCULWGh94iYp/tFZJ+rJGhtzUR8XRlnQGoVFPj7BHxgKQHKuoFQAtxuiyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDWLK7qfp5b/E0/5yOyWbv+ZPz+6bm34sP3FdY9auLNYP+wbLtb/97pD6tYe7/1+cd1dw28V6yffs7JYP+bPHinWO6GpsNveJukNScOS9kVEbxVNAaheFXv234+IXRW8DoAW4jM7kESzYQ9JP7H9mO3lYz3B9nLbfbb7hrSnyc0BaFSzh/FLI2KH7TmS1tv+ZUQ8PPoJEbFa0mpJOsI90eT2ADSoqT17ROyo3e6UdJ+kJVU0BaB6DYfd9gzbMw/cl3S2pM1VNQagWs0cxs+VdJ/tA69zR0T8qJKuJpkpxy0q1mP6tGJ9xxkfKtbfPqX+mHDPB8vjxT/9dHm8uZP+49czi/V/+OdzivWNJ95Rt/bi0NvFdVcNfLZY/9hPD75PpA2HPSK2Svp0hb0AaCGG3oAkCDuQBGEHkiDsQBKEHUiCS1wrMHzmZ4r16269sVj/5LT6l2JOZkMxXKz/9Q1fLdanvlUe/jr1nhV1azNf3ldcd/qu8tDcYX0bi/VuxJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0C05/ZUaw/9pv5xfonpw1U2U6lVvafUqxvfbP8U9S3LvxB3drr+8vj5HP/6T+L9VY6+C5gHR97diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHtG1E8wj1xss9q2/a6xeAlpxbru88p/9zzlCcPL9af+MYN77unA67d9bvF+qNnlMfRh197vViPU+v/APG2bxVX1YJlT5SfgPfYGBu0OwbHnMuaPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exeYMvvDxfrwq4PF+ot31B8rf/r0NcV1l/z9N4v1OTd27ppyvH9NjbPbXmN7p+3No5b12F5v+7na7awqGwZQvYkcxt8q6d2z3l8paUNELJK0ofYYQBcbN+wR8bCkdx9Hnidpbe3+WknnV9wXgIo1+gXd3Ijol6Ta7Zx6T7S93Haf7b4h7WlwcwCa1fJv4yNidUT0RkTvNE1v9eYA1NFo2Adsz5Ok2u3O6loC0AqNhn2dpItr9y+WdH817QBolXF/N972nZLOlDTb9nZJV0taJelu25dKeknSha1scrIb3vVqU+sP7W58fvdPffkXxforN00pv8D+8hzr6B7jhj0iltUpcXYMcBDhdFkgCcIOJEHYgSQIO5AEYQeSYMrmSeC4K56tW7vkxPKgyb8dtaFYP+PCy4r1md9/pFhH92DPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+CZSmTX7168cV131p3dvF+pXX3las/8UXLyjW478/WLc2/+9+XlxXbfyZ8wzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEkzZnNzgH55arN9+9XeK9QVTD21425+6bUWxvujm/mJ939ZtDW97smpqymYAkwNhB5Ig7EAShB1IgrADSRB2IAnCDiTBODuKYuniYv2IVduL9Ts/8eOGt33sg39UrP/O39S/jl+Shp/b2vC2D1ZNjbPbXmN7p+3No5ZdY/tl25tqf+dW2TCA6k3kMP5WSeeMsfx7EbG49vdAtW0BqNq4YY+IhyUNtqEXAC3UzBd0K2w/WTvMn1XvSbaX2+6z3TekPU1sDkAzGg37TZIWSlosqV/Sd+s9MSJWR0RvRPRO0/QGNwegWQ2FPSIGImI4IvZLulnSkmrbAlC1hsJue96ohxdI2lzvuQC6w7jj7LbvlHSmpNmSBiRdXXu8WFJI2ibpaxFRvvhYjLNPRlPmzinWd1x0TN3axiuuL677gXH2RV9+8exi/fXTXi3WJ6PSOPu4k0RExLIxFt/SdFcA2orTZYEkCDuQBGEHkiDsQBKEHUiCS1zRMXdvL0/ZfJgPKdZ/HXuL9c9/8/L6r33fxuK6Byt+ShoAYQeyIOxAEoQdSIKwA0kQdiAJwg4kMe5Vb8ht/2nln5J+4cLylM0nLN5WtzbeOPp4bhg8qVg/7P6+pl5/smHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+ybn3hGL92W+Vx7pvXrq2WD/90PI15c3YE0PF+iODC8ovsH/cXzdPhT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPtBYOqCo4r1Fy75WN3aNRfdVVz3C4fvaqinKlw10FusP3T9KcX6rLXl353HO427Z7c93/aDtrfYftr2t2vLe2yvt/1c7XZW69sF0KiJHMbvk7QyIo6TdIqky2wfL+lKSRsiYpGkDbXHALrUuGGPiP6IeLx2/w1JWyQdKek8SQfOpVwr6fxWNQmgee/rCzrbR0s6SdJGSXMjol8a+QdB0pw66yy33We7b0h7musWQMMmHHbbh0v6oaTLI2L3RNeLiNUR0RsRvdM0vZEeAVRgQmG3PU0jQb89Iu6tLR6wPa9WnydpZ2taBFCFcYfebFvSLZK2RMR1o0rrJF0saVXt9v6WdDgJTD36t4v1139vXrF+0d/+qFj/kw/dW6y30sr+8vDYz/+l/vBaz63/VVx31n6G1qo0kXH2pZK+Iukp25tqy67SSMjvtn2ppJckXdiaFgFUYdywR8TPJI05ubuks6ptB0CrcLoskARhB5Ig7EAShB1IgrADSXCJ6wRNnffRurXBNTOK6359wUPF+rKZAw31VIUVL59WrD9+U3nK5tk/2Fys97zBWHm3YM8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkGWff+wflny3e+6eDxfpVxzxQt3b2b73VUE9VGRh+u27t9HUri+se+1e/LNZ7XiuPk+8vVtFN2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJpxtm3nV/+d+3ZE+9p2bZvfG1hsX79Q2cX6x6u9+O+I4699sW6tUUDG4vrDhermEzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo6I8hPs+ZJuk/RRjVy+vDoirrd9jaQ/lvRK7alXRUT9i74lHeGeONlM/Aq0ysbYoN0xOOaJGRM5qWafpJUR8bjtmZIes72+VvteRHynqkYBtM5E5mfvl9Rfu/+G7S2Sjmx1YwCq9b4+s9s+WtJJkg6cg7nC9pO219ieVWed5bb7bPcNaU9TzQJo3ITDbvtwST+UdHlE7JZ0k6SFkhZrZM//3bHWi4jVEdEbEb3TNL2ClgE0YkJhtz1NI0G/PSLulaSIGIiI4YjYL+lmSUta1yaAZo0bdtuWdIukLRFx3ajl80Y97QJJ5ek8AXTURL6NXyrpK5Kesr2ptuwqSctsL5YUkrZJ+lpLOgRQiYl8G/8zSWON2xXH1AF0F86gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDHuT0lXujH7FUn/M2rRbEm72tbA+9OtvXVrXxK9NarK3o6KiI+MVWhr2N+zcbsvIno71kBBt/bWrX1J9NaodvXGYTyQBGEHkuh02Fd3ePsl3dpbt/Yl0Vuj2tJbRz+zA2ifTu/ZAbQJYQeS6EjYbZ9j+xnbz9u+shM91GN7m+2nbG+y3dfhXtbY3ml786hlPbbX236udjvmHHsd6u0a2y/X3rtNts/tUG/zbT9oe4vtp21/u7a8o+9doa+2vG9t/8xue4qkZyV9VtJ2SY9KWhYRv2hrI3XY3iapNyI6fgKG7dMlvSnptog4obbsHyUNRsSq2j+UsyLiii7p7RpJb3Z6Gu/abEXzRk8zLul8SV9VB9+7Ql9fVBvet07s2ZdIej4itkbEXkl3STqvA310vYh4WNLguxafJ2lt7f5ajfzP0nZ1eusKEdEfEY/X7r8h6cA04x197wp9tUUnwn6kpF+Nerxd3TXfe0j6ie3HbC/vdDNjmBsR/dLI/zyS5nS4n3cbdxrvdnrXNONd8941Mv15szoR9rGmkuqm8b+lEfEZSZ+TdFntcBUTM6FpvNtljGnGu0Kj0583qxNh3y5p/qjHH5e0owN9jCkidtRud0q6T903FfXAgRl0a7c7O9zP/+umabzHmmZcXfDedXL6806E/VFJi2wvsH2IpC9JWteBPt7D9ozaFyeyPUPS2eq+qajXSbq4dv9iSfd3sJd36JZpvOtNM64Ov3cdn/48Itr+J+lcjXwj/4Kkv+xED3X6+oSkJ2p/T3e6N0l3auSwbkgjR0SXSvqwpA2Snqvd9nRRb/8u6SlJT2okWPM61NtpGvlo+KSkTbW/czv93hX6asv7xumyQBKcQQckQdiBJAg7kARhB5Ig7EAShB1IgrADSfwfs4RxaLJFjqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se puede visualizar una de estas imágenes para conocer el conjunto de datos\n",
    "plt.imshow(x_train[0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n",
    "\n",
    "Ahora se deben ajustar los datos de entrada para que sean consistentes con las capas de la CNN en `keras`. En este caso se va a agregar una dimensión adicional hasta el final del _tensor_ de datos para afirmar que existe solamente un canal de colores.\n",
    "\n",
    "El tamaño de las imágenes es ahora **(número de ejemplos, ancho, alto, número de canales)** en ese orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reajustar las imágenes para asegurar que solamente es un canal de color\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "# Tamaño de la entrada, en forma de tupla siempre\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un paso adicional para asegurar que todo es consistente es convertir los datos a `float32` para mejor manejo con el CPU/GPU (recordar que las GPU solamente pueden trabajar con flotantes de 32 bits).\n",
    "\n",
    "Adicionalmente, se normalizan las entradas para dejar en flotantes los valores de cada pixel, dividiendo por el total que pueden adquirir como valor. Esto para seguir con el manejo de la CNN y consistencia a lo largo del entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a float32 para mejor manejo\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "# Normalizar los valores de las imágenes\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (60000, 28, 28, 1)\n",
      "60000 Muestras de entrenamiento\n",
      "10000 Muestras de prueba\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del conjunto de entrenamiento:\", x_train.shape)\n",
    "print(x_train.shape[0], \"Muestras de entrenamiento\")\n",
    "print(x_test.shape[0], \"Muestras de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto nos aseguramos de todos los pasos que hemos hecho hasta ahora. Todo parece estar en orden, teniendo 60000 imágenes de entrenamiento y 10000 de prueba.\n",
    "\n",
    "El último paso de preprocesamiento es hacer la codificación _one-hot_ para las etiquetas, que se puede realizar fácilmente en `keras`, o alternativamente en `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encoding para las etiquetas\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Está representación dice que esta entrada en particular pertenece al\n",
    "# dígito 6 en el conjunto de datos\n",
    "y_train[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura de la CNN\n",
    "\n",
    "Siguiendo el ejemplo de `keras` se toma la siguiente arquitectura:\n",
    "\n",
    "- La **entrada** consta de una capa convolucional de 32 unidades. El _kernel_ de convolución es de $3 \\times 3$ y tiene una función de activación ReLU. No tiene **relleno** en los bordes, por lo que al final de esta capa el tamaño de las imágenes se verá reducido.\n",
    "\n",
    "- La **primera capa oculta** consta de una capa convolucional de 64 unidades, con un _kernel_ de $3 \\times 3$ y función de activación ReLU. Después de esto se aplica una capa de agrupación o _pooling_ de tipo máximo, lo que seleccionará el máximo valor entre los 2 vecinos más cercanos, en este caso en particular.\n",
    "\n",
    "- La **segunda capa oculta** consta de un _aplanamiento_ espacial de las imágenes, lo que las hará vectores unidimensionales, y una red neuronal totalmente conectada de 128 unidades con función de activación ReLU.\n",
    "\n",
    "- La **capa de salida** consta del número total de clases y la función de activación _softmax_ para clasificación.\n",
    "\n",
    "Este diseño consta entonces de dos partes, la primera parte para aprender **características** mediante las dos capas convolucionales, y la última parte con dos capas para la **clasificación** efectiva del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0812 18:44:18.485925 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arquitectura = [\n",
    "    layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation=\"relu\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 18:44:18.658162 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0812 18:44:18.662040 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0812 18:44:18.684660 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se construye el modelo con este diseño\n",
    "model = models.Sequential(arquitectura)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización y entrenamiento\n",
    "\n",
    "Para optimizar y medir la eficacia de este modelo se optó por el optimizador [NADAM](http://cs229.stanford.edu/proj2015/054_report.pdf) que facilita el aprendizaje en arquitecturas grandes al tener un ratio de aprendizaje autoajustable, y la _precisión_ como medida de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 18:44:19.098011 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0812 18:44:19.121213 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se entrena el modelo, separando un 20% del conjunto de entrenamiento como conjunto de validación, para dejar el conjunto de prueba como evaluación de la generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 18:44:19.368462 140605282740032 deprecation.py:323] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0812 18:44:19.429847 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.1511 - acc: 0.9535 - val_loss: 0.0768 - val_acc: 0.9770\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 53s 1ms/step - loss: 0.0379 - acc: 0.9877 - val_loss: 0.0504 - val_acc: 0.9848\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 53s 1ms/step - loss: 0.0226 - acc: 0.9928 - val_loss: 0.0411 - val_acc: 0.9887\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 53s 1ms/step - loss: 0.0145 - acc: 0.9950 - val_loss: 0.0466 - val_acc: 0.9877\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 53s 1ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 0.0554 - val_acc: 0.9862\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 53s 1ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0468 - val_acc: 0.9902\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 53s 1ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0517 - val_acc: 0.9881\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0690 - val_acc: 0.9852\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0522 - val_acc: 0.9881\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0536 - val_acc: 0.9889\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0874 - val_acc: 0.9822\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0566 - val_acc: 0.9897\n",
      "CPU times: user 28min 37s, sys: 18.3 s, total: 28min 56s\n",
      "Wall time: 10min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0e8cd59d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se observa el valor de `acc`, la precisión en el conjunto de entrenamiento, y `val_acc` la precisión en el conjunto de validación, existe una diferencia notable, con 99.6% y 98.7% en promedio, respectivamente.\n",
    "\n",
    "Esto implica que el modelo está **sobreajustado**, y aunque pareciera que son algunos decimales, en realidad está _bastante_ **sobreajustado**. Para comprobar este resultado, se evaluará el modelo entrenado en el conjunto de prueba que se reservó desde el principio, recordando que este conjunto nunca fue visto por el modelo; con esto se podrá comprobar la verdadera generalización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 0.05335224215239669\n",
      "Precisión del conjunto de prueba: 0.9879\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperarse, la _precisión_ en el conjunto de prueba se parece más al valor encontrado por la precisión del conjunto de validación, esto es el valor de `val_acc` en el modelo antes mostrado.\n",
    "\n",
    "Esto demuestra que el modelo está efectivamente **sobreajustado**, y no por un margen pequeño (aunque lo parezca).\n",
    "\n",
    "La pregunta aquí es: ¿qué se puede hacer para mejorarlo? ¿Esto se debe al diseño de la CNN? ¿Se debe a la elección de hiperparámetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "- La arquitectura de esta CNN no es única, ¿será posible mejorar el valor de precisión? Modificar el número de unidades en las capas excepto la salida para comprobar si esto es posible.\n",
    "\n",
    "- El sobreajuste del modelo se puede deber a varias razones, ¿cuáles son las más probables?\n",
    "\n",
    "- Cada capa convolucional, al no tener relleno, reduce el tamaño de cada imágen. Calcular estos tamaños y el tamaño final del vector de información para saber el efecto de tener relleno o no. ¿Qué pasaría si se le pone relleno? Experimentar con las opciones de relleno en `keras`.\n",
    "\n",
    "- La capa de _pooling_ no es única, modificar usando las distintas implementaciones de `keras`. ¿Esto afecta positivamente al resultado del modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soluciones\n",
    "\n",
    "### 1.\n",
    "Se propone la siguiente nueva arquitectura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se propone la siguiente nueva arquitectura\n",
    "nueva_arquitectura = [\n",
    "    layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation=\"relu\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(254, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential(nueva_arquitectura)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 165s 3ms/step - loss: 0.1335 - acc: 0.9583 - val_loss: 0.0472 - val_acc: 0.9866\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 164s 3ms/step - loss: 0.0329 - acc: 0.9893 - val_loss: 0.0434 - val_acc: 0.9884\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0175 - acc: 0.9937 - val_loss: 0.0536 - val_acc: 0.9865\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0135 - acc: 0.9954 - val_loss: 0.0601 - val_acc: 0.9857\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0118 - acc: 0.9960 - val_loss: 0.0426 - val_acc: 0.9897\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0469 - val_acc: 0.9876\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 164s 3ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0484 - val_acc: 0.9887\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0056 - acc: 0.9979 - val_loss: 0.0660 - val_acc: 0.9882\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0607 - val_acc: 0.9891\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0646 - val_acc: 0.9873\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0619 - val_acc: 0.9889\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 164s 3ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0699 - val_acc: 0.9864\n",
      "CPU times: user 1h 38min 7s, sys: 38.4 s, total: 1h 38min 46s\n",
      "Wall time: 32min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0ad5325d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 0.07060163489125994\n",
      "Precisión del conjunto de prueba: 0.9868\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto se comprueba que **no** se elimina el sobreajuste presente; lo más acertado sería emplear algún tipo de _regularización._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "\n",
    "Las causas más probables del sobreajuste es la falta de _regularización,_ el _bajo_ número de ejemplos en el conjunto de datos, y posiblemente el diseño de la arquitectura (quizás hacen falta capas adicionales de convolución)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "Tan simple como llamar el _resumen_ del modelo de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 254)               4681982   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2550      \n",
      "=================================================================\n",
      "Total params: 4,759,028\n",
      "Trainable params: 4,759,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cálculo de ~ 5 millones de parámetros, mientras se tienen 60000 ejemplos, hace más evidente el sobreajuste del modelo. Claramente, al no tener relleno en la convolución, la arquitectura reduce el tamaño de las imágenes.\n",
    "\n",
    "La siguiente arquitectura coloca relleno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se propone la siguiente nueva arquitectura, ahora con relleno\n",
    "nueva_arquitectura = [\n",
    "    layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                  strides=1,\n",
    "                  padding=\"same\",\n",
    "                 activation=\"relu\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                  strides=1,\n",
    "                  padding=\"same\",\n",
    "                  activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential(nueva_arquitectura)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.1550 - acc: 0.9522 - val_loss: 0.0579 - val_acc: 0.9830\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.0382 - acc: 0.9879 - val_loss: 0.0494 - val_acc: 0.9862\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.0444 - val_acc: 0.9874\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 66s 1ms/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.0520 - val_acc: 0.9869\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0472 - val_acc: 0.9888\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0525 - val_acc: 0.9871\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.0658 - val_acc: 0.9866\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0547 - val_acc: 0.9867\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0644 - val_acc: 0.9878\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0631 - val_acc: 0.9867\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0058 - acc: 0.9979 - val_loss: 0.0662 - val_acc: 0.9860\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0634 - val_acc: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe092604910>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 0.06149152019040234\n",
      "Precisión del conjunto de prueba: 0.9863\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,625,866\n",
      "Trainable params: 1,625,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se aplica _padding_ el número de parámetros a calcular se **reduce** de forma _muy considerable_, pasa de ser ~ 5 millones a ~ 1.6 millones de parámetros, algo sustancial. Esto hace que el entrenamiento sea más rápido.\n",
    "\n",
    "Por otro lado, no mejora el rendimiento ni la eficacia de clasificación, por lo que el problema reside en otro lado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "Para atacar el ejercicio de _pooling_ se propone la siguiente arquitectura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se propone la siguiente nueva arquitectura, ahora con relleno\n",
    "nueva_arquitectura = [\n",
    "    layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                  strides=1,\n",
    "                  padding=\"same\",\n",
    "                 activation=\"relu\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                  strides=1,\n",
    "                  padding=\"same\",\n",
    "                  activation=\"relu\"),\n",
    "    layers.AveragePooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 20:52:14.468607 140605282740032 deprecation_wrapper.py:119] From /home/edwinb/anaconda3/envs/deep_workshop/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential(nueva_arquitectura)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/12\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.1584 - acc: 0.9508 - val_loss: 0.0614 - val_acc: 0.9820\n",
      "Epoch 2/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0415 - acc: 0.9871 - val_loss: 0.0458 - val_acc: 0.9864\n",
      "Epoch 3/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0411 - val_acc: 0.9879\n",
      "Epoch 4/12\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0170 - acc: 0.9948 - val_loss: 0.0507 - val_acc: 0.9862\n",
      "Epoch 5/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0124 - acc: 0.9957 - val_loss: 0.0490 - val_acc: 0.9884\n",
      "Epoch 6/12\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0113 - acc: 0.9962 - val_loss: 0.0433 - val_acc: 0.9882\n",
      "Epoch 7/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.0488 - val_acc: 0.9882\n",
      "Epoch 8/12\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0665 - val_acc: 0.9861\n",
      "Epoch 9/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0533 - val_acc: 0.9891\n",
      "Epoch 10/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0577 - val_acc: 0.9875\n",
      "Epoch 11/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0596 - val_acc: 0.9871\n",
      "Epoch 12/12\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0585 - val_acc: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0918afc50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 0.047910731923198134\n",
      "Precisión del conjunto de prueba: 0.9889\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,625,866\n",
      "Trainable params: 1,625,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver en el resumen del modelo que no afecta demasiado al número de parámetros el haber modificado la capa de agrupación o _pooling,_ por lo que se puede descartar que este hecho en realidad sea relevante, al menos en este ejemplo. En otros casos será importante experimentar con este tipo de capas según sea el problema en cuestión.\n",
    "\n",
    "Por otro lado, el tiempo de cómputo aumentó 1 segundo por cada época de entrenamiento, por lo que es importante notar que _no_ tuvo un efecto _positivo_ en la precisión de clasificación, pero _si_ tuvo un efecto _negativo_ en el tiempo de entrenamiento. En este caso se puede descartar fácilmente el cambiar la capa de _pooling_ de tomar el promedio (`AveragePooling2D`) a tomar el máximo (`MaxPooling2D`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
