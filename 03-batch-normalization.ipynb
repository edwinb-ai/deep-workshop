{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización por lote (Batch Normalization)\n",
    "\n",
    "Propuesto for [Ioffe & Szegedy](https://arxiv.org/pdf/1502.03167.pdf) es un método para acelerar el entrenamiento mediante la normalización de los valores de los pesos en cada región de la red neuronal. El libro de Deep Learning en el [capítulo de regularización](https://www.deeplearningbook.org/contents/regularization.html) hace un excelente trabajo de explicar el porqué se necesita y cómo se puede utilizar en redes neuronales convolucionales (CNN).\n",
    "\n",
    "En este documento se expondrán las diferencias de entrenar una CNN con y sin normalización por lote (BN) para ver sus efectos en el entrenamiento de una CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Nadam, RMSprop, Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre, se inicializan los hiperparámetros para el conjunto de datos en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epocas = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "En este documento se trabajará con el conjunto de datos [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que es un conjunto de 60000 imágenes de tamaño $32 \\times 32$, a color, y que contienen 10 clases diferentes. La información del conjunto de datos se puede ver en el sitio web vinculado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de x_train: (50000, 32, 32, 3)\n",
      "50000 Ejemplos de entrenamiento\n",
      "10000 Ejemplos de prueba\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de x_train:\", x_train.shape)\n",
    "print(x_train.shape[0], \"Ejemplos de entrenamiento\")\n",
    "print(x_test.shape[0], \"Ejemplos de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se puede observar una de las imágenes, solamente para hacer un poco de exploración del conjunto de datos y conocerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5720f39d10>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1, :, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es costumbre, se cambia el tipo a `float32` y se normalizan los valores de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, se cambian las etiquetas de las clases utilizando codificación _one hot._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño básico (sin BN)\n",
    "\n",
    "En este diseño no se va a incorporar BN. Este diseño fue tomado del [ejemplo de `keras`](https://keras.io/examples/cifar10_cnn/) para CNN y clasificación, pero modificado para su uso en este documento.\n",
    "\n",
    "La arquitectura es la siguiente:\n",
    "\n",
    "- La **primera** capa es de convolución con 32 unidades, con relleno de $3 \\times 3$, y función de activación ReLU.\n",
    "- La **segunda** capa también es de convolución con 32 unidades, sin relleno, y función de activación ReLU.\n",
    "- A estas dos capas le sigue una capa de _max pooling_ de $2 \\times 2$.\n",
    "- La **tercera** capa es de convolución con 64 unidades, con relleno de $3 \\times 3$, y función de activación ReLU.\n",
    "- La **cuarta** capa también es de convolución con 64 unidades, sin relleno, y función de activación ReLU.\n",
    "- A estas dos capas le sigue una nueva capa de _max pooling_ de $2 \\times 2$; aquí termina la etapa de características\n",
    "- Con la etapa de clasificación se **aplanan** las imágenes y se ingresan a una red neuronal totalmente conectada de 512 unidades con función de activación ReLU.\n",
    "- La **capa de salida** tiene tantas unidades como clases y función de activación softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquitectura_basica = [\n",
    "    # Capa de entrada, primera capa de características\n",
    "    Conv2D(32, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           activation=\"relu\",\n",
    "           input_shape=x_train.shape[1:]),\n",
    "    Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Segunda capa de características\n",
    "    Conv2D(64, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           activation=\"relu\"),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Capa totalmente conectada\n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    # Capa de salida\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño normalizado (con BN)\n",
    "\n",
    "En este diseño se incorpora BN. Este diseño es el mismo que el anterior, la única diferencia es que antes de cualquier función de activación se aplica la normalización, para alimentar a la función de activación con los valores normalizados.\n",
    "\n",
    "Dos puntos importantes a mencionar:\n",
    "\n",
    "- Se quita el **sesgo** de cada capa, siguiendo las recomendaciones del artículo original. Esto porque cuando se normalizan los valores de cada capa el sesgo se elimina en el proceso de normalización y no hace falta calcularlo.\n",
    "- Se pone la opción `scale=False` dado que la media será calculada por la función de activación ReLU. En cualquier otro caso se debe de quitar esta opción dado que no siempre es cierta esta hipótesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todas las capas normalizadas, excpeto la última\n",
    "arquitectura_norm = [\n",
    "    # Capa de entrada, primera capa de características\n",
    "    Conv2D(32, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           input_shape=x_train.shape[1:],\n",
    "           use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(32, (3, 3), use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Segunda capa de características\n",
    "    Conv2D(64, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(64, (3, 3), use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Capa totalmente conectada\n",
    "    Flatten(),\n",
    "    Dense(512),\n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    # Capa de salida\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y pruebas\n",
    "\n",
    "Se construyen los modelos a partir de estas arquitecturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_basico = Sequential(arquitectura_basica)\n",
    "model_normalizado = Sequential(arquitectura_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador\n",
    "\n",
    "Para el **optimizador** se tiene que notar lo siguiente: el hecho de poder aplicar BN hacer que los ratios de aprendizaje sean mayores, mientras que la arquitectura sin BN siempre debe tener ratio pequeños. Esto se va a aplicar directamente a los optimizadores, donde se utilizará el confiable _Nadam_ con ratio de aprendizaje 0.002 para el caso _básico,_ mientras que para el caso _normalizado_ se aplicará con un ratio de aprendizaje de 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_basico.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#model_basico.fit(x_train, y_train,\n",
    "#              batch_size=batch_size,\n",
    "#              epochs=epocas,\n",
    "#              validation_data=(x_test, y_test),\n",
    "#              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 2.30138900642395\n",
      "Precisión del conjunto de prueba: 0.1074\n"
     ]
    }
   ],
   "source": [
    "score = model_basico.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que la precisión no es tan buena, y es de esperarse. Sin embargo el valor de la pérdida es _bastante_ grande. Aprximadamente 2.29 es demasiado error, y este el caso sin BN.\n",
    "\n",
    "Claramente el modelo está sobreajustado, pero además al modelo le cuesta demasiado trabajo ser entrenado, por lo que el error es tan grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normalizado.compile(loss=\"categorical_crossentropy\",\n",
    "                          optimizer=Nadam(),\n",
    "                          metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso normalizado, se entrenará el modelo en la mitad de las épocas y con un ratio de aprendizaje más grande, como ya se había mencionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 1.4873 - acc: 0.4875 - val_loss: 1.0287 - val_acc: 0.6343\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 151s 3ms/step - loss: 0.9873 - acc: 0.6566 - val_loss: 0.9849 - val_acc: 0.6416\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 152s 3ms/step - loss: 0.8296 - acc: 0.7149 - val_loss: 1.0667 - val_acc: 0.6386\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 152s 3ms/step - loss: 0.7324 - acc: 0.7475 - val_loss: 0.7555 - val_acc: 0.7424\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 0.6550 - acc: 0.7756 - val_loss: 0.7187 - val_acc: 0.7530\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 0.5834 - acc: 0.7979 - val_loss: 0.8368 - val_acc: 0.7278\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.5238 - acc: 0.8165 - val_loss: 0.6645 - val_acc: 0.7766\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.4744 - acc: 0.8366 - val_loss: 0.7922 - val_acc: 0.7499\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.4249 - acc: 0.8506 - val_loss: 0.8014 - val_acc: 0.7496\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.3874 - acc: 0.8648 - val_loss: 0.7867 - val_acc: 0.7544\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 155s 3ms/step - loss: 0.3559 - acc: 0.8766 - val_loss: 0.6832 - val_acc: 0.7959\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.3229 - acc: 0.8863 - val_loss: 0.7814 - val_acc: 0.7705\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.2946 - acc: 0.8971 - val_loss: 0.7896 - val_acc: 0.7789\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 167s 3ms/step - loss: 0.2733 - acc: 0.9029 - val_loss: 0.8200 - val_acc: 0.7847\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 0.2540 - acc: 0.9100 - val_loss: 0.8280 - val_acc: 0.7780\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.2366 - acc: 0.9171 - val_loss: 0.8161 - val_acc: 0.7894\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 154s 3ms/step - loss: 0.2200 - acc: 0.9241 - val_loss: 0.8577 - val_acc: 0.7854\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 156s 3ms/step - loss: 0.2100 - acc: 0.9274 - val_loss: 0.8445 - val_acc: 0.7955\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 153s 3ms/step - loss: 0.2019 - acc: 0.9310 - val_loss: 0.8939 - val_acc: 0.7916\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 165s 3ms/step - loss: 0.1886 - acc: 0.9356 - val_loss: 0.9781 - val_acc: 0.7711\n",
      "CPU times: user 2h 16min 53s, sys: 2min 20s, total: 2h 19min 14s\n",
      "Wall time: 51min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5720873ad0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_normalizado.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epocas // 2,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 0.9781216808319092\n",
      "Precisión del conjunto de prueba: 0.7711\n"
     ]
    }
   ],
   "source": [
    "score = model_normalizado.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que nada es importante observar que el tiempo de entrenamiento se redujo, no considerablmente pero se ahorró un poco más de tiempo. Esto se debe a que se emplearon menos épocas de entrenamiento, como se había considerado. Es cierto que el tiempo de entrenamiento _por época_ incrementó, pero esto era de esperarse pues ahora cada capa de calcular su normalización y adicionalmente hacer el cálculo correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones y conclusiones\n",
    "\n",
    "Mejoró la precisión del modelo al agregar `Dropout` al final, en la capa totalmente conectada, y un entrenamiento de 20 épocas. El tiempo de entrenamiento sigue siendo grande, pero es de esperarse para un conjunto de datos tan grande.\n",
    "\n",
    "Observar también que el ratio de aprendizaje se dejó en el default de `lr=0.002` lo que es un tanto contrdictorio, dado que el propósito de BN es utilizar ratios de aprendizajes grandes, pero quizás con otras metodologías se puede mejorar este resultado."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
