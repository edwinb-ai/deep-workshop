{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización por lote (Batch Normalization)\n",
    "\n",
    "Propuesto for [Ioffe & Szegedy](https://arxiv.org/pdf/1502.03167.pdf) es un método para acelerar el entrenamiento mediante la normalización de los valores de los pesos en cada región de la red neuronal. El libro de Deep Learning en el [capítulo de regularización](https://www.deeplearningbook.org/contents/regularization.html) hace un excelente trabajo de explicar el porqué se necesita y cómo se puede utilizar en redes neuronales convolucionales (CNN).\n",
    "\n",
    "En este documento se expondrán las diferencias de entrenar una CNN con y sin normalización por lote (BN) para ver sus efectos en el entrenamiento de una CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Nadam, RMSprop, Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre, se inicializan los hiperparámetros para el conjunto de datos en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epocas = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "En este documento se trabajará con el conjunto de datos [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que es un conjunto de 60000 imágenes de tamaño $32 \\times 32$, a color, y que contienen 10 clases diferentes. La información del conjunto de datos se puede ver en el sitio web vinculado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de x_train: (50000, 32, 32, 3)\n",
      "50000 Ejemplos de entrenamiento\n",
      "10000 Ejemplos de prueba\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de x_train:\", x_train.shape)\n",
    "print(x_train.shape[0], \"Ejemplos de entrenamiento\")\n",
    "print(x_test.shape[0], \"Ejemplos de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se puede observar una de las imágenes, solamente para hacer un poco de exploración del conjunto de datos y conocerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f90576ac210>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1, :, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es costumbre, se cambia el tipo a `float32` y se normalizan los valores de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, se cambian las etiquetas de las clases utilizando codificación _one hot._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño básico (sin BN)\n",
    "\n",
    "En este diseño no se va a incorporar BN. Este diseño fue tomado del [ejemplo de `keras`](https://keras.io/examples/cifar10_cnn/) para CNN y clasificación, pero modificado para su uso en este documento.\n",
    "\n",
    "La arquitectura es la siguiente:\n",
    "\n",
    "- La **primera** capa es de convolución con 32 unidades, con relleno de $3 \\times 3$, y función de activación ReLU.\n",
    "- La **segunda** capa también es de convolución con 32 unidades, sin relleno, y función de activación ReLU.\n",
    "- A estas dos capas le sigue una capa de _max pooling_ de $2 \\times 2$.\n",
    "- La **tercera** capa es de convolución con 64 unidades, con relleno de $3 \\times 3$, y función de activación ReLU.\n",
    "- La **cuarta** capa también es de convolución con 64 unidades, sin relleno, y función de activación ReLU.\n",
    "- A estas dos capas le sigue una nueva capa de _max pooling_ de $2 \\times 2$; aquí termina la etapa de características\n",
    "- Con la etapa de clasificación se **aplanan** las imágenes y se ingresan a una red neuronal totalmente conectada de 512 unidades con función de activación ReLU.\n",
    "- La **capa de salida** tiene tantas unidades como clases y función de activación softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquitectura_basica = [\n",
    "    # Capa de entrada, primera capa de características\n",
    "    Conv2D(32, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           activation=\"relu\",\n",
    "           input_shape=x_train.shape[1:]),\n",
    "    Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Segunda capa de características\n",
    "    Conv2D(64, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           activation=\"relu\"),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Capa totalmente conectada\n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\"),\n",
    "    # Capa de salida\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño normalizado (con BN)\n",
    "\n",
    "En este diseño se incorpora BN. Este diseño es el mismo que el anterior, la única diferencia es que antes de cualquier función de activación se aplica la normalización, para alimentar a la función de activación con los valores normalizados.\n",
    "\n",
    "Dos puntos importantes a mencionar:\n",
    "\n",
    "- Se quita el **sesgo** de cada capa, siguiendo las recomendaciones del artículo original. Esto porque cuando se normalizan los valores de cada capa el sesgo se elimina en el proceso de normalización y no hace falta calcularlo.\n",
    "- Se pone la opción `scale=False` dado que la media será calculada por la función de activación ReLU. En cualquier otro caso se debe de quitar esta opción dado que no siempre es cierta esta hipótesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todas las capas normalizadas, excpeto la última\n",
    "arquitectura_norm = [\n",
    "    # Capa de entrada, primera capa de características\n",
    "    Conv2D(32, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           input_shape=x_train.shape[1:],\n",
    "           use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(32, (3, 3), use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Segunda capa de características\n",
    "    Conv2D(64, kernel_size=(3, 3),\n",
    "           padding=\"same\",\n",
    "           use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(64, (3, 3), use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Capa totalmente conectada\n",
    "    Flatten(),\n",
    "    Dense(512, use_bias=False),\n",
    "    BatchNormalization(scale=False),\n",
    "    Activation(\"relu\"),\n",
    "    # Capa de salida\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y pruebas\n",
    "\n",
    "Se construyen los modelos a partir de estas arquitecturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_basico = Sequential(arquitectura_basica)\n",
    "model_normalizado = Sequential(arquitectura_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador\n",
    "\n",
    "Para el **optimizador** se tiene que notar lo siguiente: el hecho de poder aplicar BN hacer que los ratios de aprendizaje sean mayores, mientras que la arquitectura sin BN siempre debe tener ratio pequeños. Esto se va a aplicar directamente a los optimizadores, donde se utilizará el confiable _Nadam_ con ratio de aprendizaje 0.002 para el caso _básico,_ mientras que para el caso _normalizado_ se aplicará con un ratio de aprendizaje de 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_basico.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 1.4312 - acc: 0.4857 - val_loss: 1.0285 - val_acc: 0.6269\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.9031 - acc: 0.6822 - val_loss: 0.8478 - val_acc: 0.7083\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.7044 - acc: 0.7505 - val_loss: 0.8490 - val_acc: 0.7144\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.5629 - acc: 0.8027 - val_loss: 0.9458 - val_acc: 0.6979\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.4362 - acc: 0.8464 - val_loss: 0.9687 - val_acc: 0.7108\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.3358 - acc: 0.8822 - val_loss: 1.0556 - val_acc: 0.7118\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.2685 - acc: 0.9049 - val_loss: 1.2723 - val_acc: 0.7039\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.2257 - acc: 0.9227 - val_loss: 1.3115 - val_acc: 0.7009\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.2050 - acc: 0.9297 - val_loss: 1.4429 - val_acc: 0.7091\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.1911 - acc: 0.9366 - val_loss: 1.6321 - val_acc: 0.7048\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.1731 - acc: 0.9424 - val_loss: 1.6294 - val_acc: 0.6958\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.1694 - acc: 0.9462 - val_loss: 1.8206 - val_acc: 0.6931\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.1717 - acc: 0.9461 - val_loss: 1.8472 - val_acc: 0.6949\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.1593 - acc: 0.9517 - val_loss: 1.9601 - val_acc: 0.6922\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.1664 - acc: 0.9495 - val_loss: 1.9455 - val_acc: 0.6936\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.1563 - acc: 0.9528 - val_loss: 1.9579 - val_acc: 0.6937\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.1482 - acc: 0.9551 - val_loss: 2.0456 - val_acc: 0.7021\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.1594 - acc: 0.9533 - val_loss: 2.1065 - val_acc: 0.6896\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.1410 - acc: 0.9589 - val_loss: 2.2846 - val_acc: 0.6877\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.1436 - acc: 0.9583 - val_loss: 2.2880 - val_acc: 0.6909\n",
      "CPU times: user 1h 31min 17s, sys: 1min 3s, total: 1h 32min 20s\n",
      "Wall time: 36min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9056eeae50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_basico.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epocas,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 2.2879998957633974\n",
      "Precisión del conjunto de prueba: 0.6909\n"
     ]
    }
   ],
   "source": [
    "score = model_basico.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que la precisión no es tan buena, y es de esperarse. Sin embargo el valor de la pérdida es _bastante_ grande. Aprximadamente 2.29 es demasiado error, y este el caso sin BN.\n",
    "\n",
    "Claramente el modelo está sobreajustado, pero además al modelo le cuesta demasiado trabajo ser entrenado, por lo que el error es tan grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normalizado.compile(loss=\"categorical_crossentropy\",\n",
    "                          optimizer=Nadam(lr=0.1),\n",
    "                          metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso normalizado, se entrenará el modelo en la mitad de las épocas y con un ratio de aprendizaje más grande, como ya se había mencionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 152s 3ms/step - loss: 1.8858 - acc: 0.3867 - val_loss: 2.7772 - val_acc: 0.3554\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 1.2749 - acc: 0.5516 - val_loss: 1.4714 - val_acc: 0.5150\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 1.0962 - acc: 0.6195 - val_loss: 2.0156 - val_acc: 0.4470\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 1.0044 - acc: 0.6532 - val_loss: 2.2228 - val_acc: 0.4059\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 0.9568 - acc: 0.6715 - val_loss: 2.3500 - val_acc: 0.3751\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 0.9070 - acc: 0.6901 - val_loss: 1.3314 - val_acc: 0.5634\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 0.8784 - acc: 0.6980 - val_loss: 1.9506 - val_acc: 0.4575\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 0.8495 - acc: 0.7103 - val_loss: 1.1463 - val_acc: 0.6175\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 0.8232 - acc: 0.7187 - val_loss: 2.5882 - val_acc: 0.4613\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 149s 3ms/step - loss: 0.8047 - acc: 0.7281 - val_loss: 1.1470 - val_acc: 0.6402\n",
      "CPU times: user 1h 8min 16s, sys: 1min 7s, total: 1h 9min 23s\n",
      "Wall time: 24min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9056622410>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_normalizado.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epocas // 2,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pérdida general del conjunto de prueba: 1.1469518697738648\n",
      "Precisión del conjunto de prueba: 0.6402\n"
     ]
    }
   ],
   "source": [
    "score = model_normalizado.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pérdida general del conjunto de prueba:\", score[0])\n",
    "print(\"Precisión del conjunto de prueba:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que nada es importante observar que el tiempo de entrenamiento se redujo, no considerablmente pero se ahorró un poco más de tiempo. Esto se debe a que se emplearon menos épocas de entrenamiento, como se había considerado. Es cierto que el tiempo de entrenamiento _por época_ incrementó, pero esto era de esperarse pues ahora cada capa de calcular su normalización y adicionalmente hacer el cálculo correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones y conclusiones\n",
    "\n",
    "Después de un largo entrenamiento se puede observar que el _error de prueba_ para el caso **normalizado** es menor que para el caso **no normalizado**, y esto es justamente lo que se esperaba. Quizás el tiempo de entrenamiento no se redujo drásticamente, pero al tener que realizar menos cálculos se obtuvo un mejor error en el caso de prueba.\n",
    "\n",
    "Por otro lado, el modelo sigue sobreajustado y no tiene buena precisión de clasificación, pero esto se modificará en futuros documentos."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
